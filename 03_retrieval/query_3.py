from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_chroma import Chroma
import time

chat = ChatOpenAI(model="gpt-3.5-turbo")
embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")
retriever = Chroma(persist_directory="./data", embedding_function=embeddings).as_retriever()
prompt = PromptTemplate.from_template("æ–‡ç« ã‚’å…ƒã«è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚\n\næ–‡ç« :\n{context}\n\nè³ªå•: {input}")

# Runnable Implementation
query = "what is kazuki minemura's skill sets?"

# æ–‡æ›¸ã‚’æ•´å½¢ã™ã‚‹é–¢æ•°
def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)
# 1. retrieve
retrieved_docs = retriever.invoke(query)
context_text = format_docs(retrieved_docs)
rag_chain = (prompt | chat | StrOutputParser())

start = time.perf_counter()
answer = rag_chain.invoke({"input": query, "context": context_text})
end = time.perf_counter()
print(f"QA in {(end - start) * 1000} milliseconds")

# 3. å‡ºåŠ›
print("ğŸ”¹ è³ªå•:")
print(query)
print("\nğŸ”¹ å›ç­”:")
print(answer)
print("\nğŸ”¹ ä½¿ã‚ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæ–‡æ›¸ï¼‰:")
for i, doc in enumerate(retrieved_docs):
    print(f"\n--- Document {i+1} ---")
    print(doc.page_content[:500])  # å¿…è¦ãªã‚‰çŸ­ãã‚«ãƒƒãƒˆ
    print(f"ğŸ“„ Metadata: {doc.metadata}")